{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1cc0f5",
   "metadata": {},
   "source": [
    "## Resampling Methods and ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3bf2240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test','mass', 'pedi', 'age', 'class']\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'\n",
    "data = pd.read_csv(url, names=names)\n",
    "print(type(data))\n",
    "array = data.values\n",
    "x = array[:,0:8] # take out class column\n",
    "y = array[:,8] # class column as a 1D list of 1s and 0s\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ce482",
   "metadata": {},
   "source": [
    "### Simple Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f0997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.12713602187287"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold # number of iterations that will divide my db, in the examples is 5\n",
    "from sklearn.model_selection import cross_val_score # validation method: cross validation and gives u a score\n",
    "from sklearn.linear_model import LogisticRegression # math model for classification (ml algorithm)\n",
    "\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True) # shuffle is the part that makes the randomness\n",
    "# logistic regression param = lbfgs is the penalty for diff between y data and predicted data (error)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "# apply everything\n",
    "results = cross_val_score(model, x, y, cv=kfold)\n",
    "results.mean() * 100 # percentage of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50edb67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0554879771295806"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.std() * 100 # std between iterations: how much each iter differs from the others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1ecaa",
   "metadata": {},
   "source": [
    "### Division by Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb580a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.55905511811024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # division by percentage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 1\n",
    "# returns you the subsets for training and testing for each x and y\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_size, random_state = seed)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "results = model.score(x_test, y_test)\n",
    "print(results * 100) # percentage of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb790f8f",
   "metadata": {},
   "source": [
    "### Cross Validation with Repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd386f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.34757347915243"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold # Cross Validation with Repetition\n",
    "from sklearn.model_selection import cross_val_score # validation method\n",
    "from sklearn.linear_model import LogisticRegression # math model for classification\n",
    "\n",
    "num_folds = 10\n",
    "num_repeated = 5\n",
    "repeatedkfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeated)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "results = cross_val_score(model, x, y, cv=repeatedkfold)\n",
    "results.mean() * 100 # percentage of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ecbf45",
   "metadata": {},
   "source": [
    "### Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7606c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.60416666666666\n",
      "41.68944689773287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score # validation method\n",
    "from sklearn.linear_model import LogisticRegression # math model for classification\n",
    "\n",
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "results = cross_val_score(model, x, y, cv=loocv)\n",
    "print(results.mean() * 100)\n",
    "print(results.std() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209936f",
   "metadata": {},
   "source": [
    "### Division by Percentage with Repetition (random 33% subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96288ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.54330708661418\n",
      "2.107310817491754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score # validation method\n",
    "from sklearn.linear_model import LogisticRegression # math model for classification\n",
    "\n",
    "test_size = 0.33\n",
    "n_splits = 10\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_size)\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size = test_size)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "results = cross_val_score(model, x, y, cv=kfold)\n",
    "print(results.mean() * 100)\n",
    "print(results.std() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb4248e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_clas = pd.read_csv(url, names=names)\n",
    "array = df_clas.values\n",
    "x_clas = array[:,0:8] # take out class column\n",
    "y_clas = array[:,8] # class column as a 1D list of 1s and 0s\n",
    "y_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbee5c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    500\n",
       "1    268\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clas.groupby('class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c01b636e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[147,  15],\n",
       "       [ 42,  50]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_size = 0.33 # 33% de 768 is 254, the sum of all in matrix var\n",
    "seed = 1\n",
    "# returns you the subsets for training and testing for each x and y\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_size, random_state = seed)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "matrix = confusion_matrix(y_test, predicted)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e844388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48140984311197077"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "test_size = 0.33 # 33% de 768 is 254, the sum of all in matrix var\n",
    "seed = 1\n",
    "# returns you the subsets for training and testing for each x and y\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_size, random_state = seed)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "cohen_score = cohen_kappa_score(y_test, predicted)\n",
    "cohen_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e64aaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.824951399951767% 0.06864369617916356\n"
     ]
    }
   ],
   "source": [
    "#AUC Area under curve (ROC)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kFold = KFold(n_splits=10, random_state = 1, shuffle = True)\n",
    "model = LogisticRegression(solver = \"lbfgs\", max_iter = 1000)\n",
    "scoring = \"roc_auc\"\n",
    "results = cross_val_score(model, x_clas, y_clas, cv=kFold, scoring = scoring)\n",
    "print(f\"AUC: {results.mean()}% {results.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0ccd08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split # validation method\n",
    "from sklearn.linear_model import LogisticRegression # math model for classification\n",
    "\n",
    "seed=1\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_clas, y_clas, test_size = test_size, random_state = seed)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "y_score = model.decision_function(x_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=model.classes_[1])\n",
    "roc_display=RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
